# Hoist Specification

**Version:** 0.1.0-draft
**Status:** Draft
**Last Updated:** January 2026

---

## Table of Contents

1. [Introduction](#1-introduction)
2. [Design Principles](#2-design-principles)
3. [Lexical Structure](#3-lexical-structure)
4. [Grammar](#4-grammar)
5. [Type System](#5-type-system)
6. [Semantics](#6-semantics)
7. [Standard Library](#7-standard-library)
8. [Execution Model](#8-execution-model)
9. [Embedding API](#9-embedding-api)
10. [Security Model](#10-security-model)
11. [Examples](#11-examples)
12. [Appendix: EBNF Grammar](#appendix-a-complete-ebnf-grammar)
13. [Appendix: Compliance Test Format](#appendix-b-compliance-test-format)

---

## 1. Introduction

### 1.1 Purpose

Hoist is a domain-specific language designed for safely exploring, transforming, and reasoning over large text contexts using Large Language Models (LLMs). It enables programmatic decomposition of long documents while maintaining strong safety guarantees suitable for production environments.

### 1.2 Motivation

Modern LLMs have limited context windows and exhibit quality degradation ("context rot") as input length increases. The Recursive Language Model (RLM) paradigm addresses this by treating context as an external environment that can be programmatically examined rather than fed directly into the model.

Hoist provides a safe, auditable language for expressing RLM-style computations without the security risks of arbitrary code execution.

### 1.3 Goals

- **Safe by construction** — No arbitrary code execution, guaranteed termination
- **LLM-native** — First-class support for LLM queries as a primitive operation
- **Embeddable** — Easy integration into any host language
- **Auditable** — Every operation is traceable and explainable
- **Expressive** — Sufficient power for complex document analysis tasks

### 1.4 Non-Goals

- Turing completeness
- General-purpose programming
- Direct I/O or network access
- Mutable state

---

## 2. Design Principles

### 2.1 Totality

Every Hoist program terminates. This is achieved by:

- No unbounded loops (`while`, `loop`)
- No general recursion (functions cannot call themselves)
- Collection operations (`map`, `filter`, `fold`) only over finite data
- Bounded iteration via `take` and `window`

### 2.2 Capability Safety

Hoist programs can only access data explicitly provided to them:

- No filesystem access
- No network access
- No environment variables
- No ambient authority

The only external interaction is through the `ask` primitive, which is implemented by the host environment.

### 2.3 Dataflow Orientation

Programs are structured as pipelines of transformations:

```
input → transform → transform → ask → transform → output
```

This makes data flow explicit, enables parallelization, and simplifies reasoning about program behavior.

### 2.4 Predictable Performance

Resource usage is bounded and predictable:

- Memory: O(n) where n is input size
- Time: O(n × k) where k is number of `ask` operations
- No hidden allocations or lazy evaluation surprises

---

## 2.5 AI-Friendly Design

Hoist is designed to be easily generated by LLMs. Key affordances:

### 2.5.1 Readable Syntax

Syntax mirrors natural language descriptions:

| Natural Language | Hoist Code |
|------------------|------------|
| "Split the context by paragraphs" | `split context by "\n\n"` |
| "Filter where it contains 'error'" | `filter items where contains(it, "error")` |
| "Map each chunk to a summary" | `map chunks with ask "Summarize: {it}"` |
| "Join results with newlines" | `join results with "\n"` |

### 2.5.2 Implicit Parameters

The `it` binding reduces boilerplate in common patterns:

```
-- LLMs naturally write this
filter items where length(it) > 0

-- Rather than this
filter items where (item → length(item) > 0)
```

### 2.5.3 Typed Output

LLMs often struggle to produce correctly formatted structured data. Typed `ask` handles this:

```
-- Instead of hoping the LLM returns valid JSON
let response = ask "List 3 fruits"
let fruits = parse_json(response)  -- May fail!

-- The runtime handles formatting and parsing
let fruits = ask "List 3 fruits" as List<String>
```

### 2.5.4 Built-in Error Recovery

LLM outputs are non-deterministic. Built-in retry and fallback reduces boilerplate:

```
-- Handles transient failures automatically
let result = ask "Complex task" with retries: 3 fallback "default"
```

### 2.5.5 Named Channels

Different tasks benefit from different models/parameters. Channels make this explicit:

```
-- Clear semantic intent
let summary = ask "Summarize: {text}" via summarizer
let code = ask "Write function: {spec}" via coder
```

### 2.5.6 Consistent Patterns

Common operations have consistent syntax, reducing LLM confusion:

```
-- All collection operations follow the same pattern
map items with transform
filter items where predicate
fold items from initial with accumulator
split text by delimiter
join items with separator
```

---

## 3. Lexical Structure

### 3.1 Character Set

Hoist source files are UTF-8 encoded. Identifiers may contain Unicode letters and digits.

### 3.2 Whitespace and Comments

Whitespace (space, tab, newline) is used to separate tokens and is otherwise insignificant.

Comments begin with `--` and extend to the end of the line:

```
-- This is a comment
chunks = split context by "\n"  -- inline comment
```

Block comments are enclosed in `{-` and `-}` and may nest:

```
{-
  This is a block comment.
  {- Nested comments are allowed -}
-}
```

### 3.3 Keywords

The following identifiers are reserved:

```
let in if then else match with
map filter fold take drop
split join window slice
ask return true false
and or not
by size stride from to where
as via retries fallback
```

### 3.4 Identifiers

Identifiers begin with a letter or underscore, followed by letters, digits, or underscores:

```
identifier = [a-zA-Z_][a-zA-Z0-9_]*
```

By convention:
- Variable names use `snake_case`
- Type names use `PascalCase`

### 3.5 Literals

#### String Literals

Double-quoted, with escape sequences:

```
"hello world"
"line1\nline2"
"tab\there"
"quote: \"nested\""
```

Escape sequences:
| Sequence | Meaning |
|----------|---------|
| `\n` | Newline |
| `\r` | Carriage return |
| `\t` | Tab |
| `\\` | Backslash |
| `\"` | Double quote |
| `\{` | Literal brace (in interpolation context) |

#### Raw String Literals

Triple-quoted strings with no escape processing:

```
"""
This is a raw string.
Backslashes \ are literal.
Quotes " don't need escaping.
"""
```

#### Interpolated Strings

Strings may contain interpolated expressions in `{}`:

```
"Hello, {name}!"
"Found {count} items in {length(chunks)} chunks"
```

Interpolation expressions must be of type `String` or a type with a `show` conversion.

#### Integer Literals

```
42
1000
0
```

Negative numbers are expressed via unary minus: `-42`

#### Boolean Literals

```
true
false
```

### 3.6 Operators and Punctuation

```
=    →    |    ,    .    :
(    )    [    ]    {    }
+    -    *    /    %
==   !=   <    >    <=   >=
++   |>
```

---

## 4. Grammar

### 4.1 Program Structure

A Hoist program consists of a sequence of bindings followed by a `return` expression:

```
program = binding* return_expr
```

Example:
```
let chunks = split context by "\n\n"
let relevant = filter chunks where contains(it, "important")
return ask "Summarize: {relevant}"
```

### 4.2 Bindings

Bindings introduce named values:

```
binding = "let" identifier (":" type)? "=" expression
```

Type annotations are optional; types are inferred when omitted.

```
let x = 42                      -- inferred as Int
let name: String = "Alice"      -- explicit annotation
let items = split text by ","   -- inferred as List<String>
```

Bindings are immutable. A name may not be rebound within the same scope.

### 4.3 Expressions

#### 4.3.1 Literals and Variables

```
expr = literal | identifier
```

#### 4.3.2 Operators

Binary operators with precedence (highest to lowest):

| Precedence | Operators | Associativity |
|------------|-----------|---------------|
| 7 | `*`, `/`, `%` | Left |
| 6 | `+`, `-`, `++` (concat) | Left |
| 5 | `==`, `!=`, `<`, `>`, `<=`, `>=` | None |
| 4 | `not` | Prefix |
| 3 | `and` | Left |
| 2 | `or` | Left |
| 1 | `\|>` (pipe) | Left |

The pipe operator passes the left operand as the first argument to the right operand:

```
context |> split by "\n" |> filter where length(it) > 0
-- equivalent to:
filter(split(context, "\n"), \it -> length(it) > 0)
```

#### 4.3.3 Conditionals

```
if_expr = "if" expression "then" expression "else" expression
```

Both branches must have the same type. There is no standalone `if` without `else`.

```
let label = if count > 10 then "many" else "few"
```

#### 4.3.4 Match Expressions

Pattern matching over values:

```
match_expr = "match" expression "with" match_arm+
match_arm = "|" pattern "→" expression
```

```
match result with
| Some(value) → "Found: {value}"
| None → "Not found"
```

Patterns:
- `_` — wildcard, matches anything
- `identifier` — binds the value to the name
- `Literal` — matches exact value
- `Constructor(patterns...)` — matches and destructures

#### 4.3.5 List Expressions

List literals:

```
[1, 2, 3]
["a", "b", "c"]
[]
```

List indexing:

```
items[0]        -- first element
items[-1]       -- last element
```

Index out of bounds returns `None` (see Optional type).

#### 4.3.6 Collection Operations

**Map** — transform each element:

```
map collection with expression
map items with upper(it)
map chunks with ask "Summarize: {it}"
```

The variable `it` is implicitly bound to each element. Alternatively, use explicit binding:

```
map chunks with chunk → ask "Summarize: {chunk}"
```

**Filter** — select elements matching a predicate:

```
filter collection where predicate
filter lines where length(it) > 0
filter items where contains(it, "error")
```

**Fold** — reduce collection to single value:

```
fold collection from initial with accumulator, element → expression
fold numbers from 0 with acc, n → acc + n
```

**Take/Drop** — limit collection size:

```
take 10 from items        -- first 10
drop 5 from items         -- skip first 5
take 10 from (drop 5 from items)  -- items 5-15
```

#### 4.3.7 String Operations

**Split** — divide string into list:

```
split text by delimiter
split document by "\n\n"     -- by paragraphs
split csv_line by ","        -- by comma
```

**Join** — combine list into string:

```
join items with separator
join words with " "
join lines with "\n"
```

**Window** — sliding window over text:

```
window text size n stride m
window document size 2000 stride 1500  -- overlapping chunks
```

Returns `List<String>`.

**Slice** — extract substring:

```
slice text from start to end
slice document from 0 to 1000
slice line from 5 to -1       -- negative index from end
```

#### 4.3.8 Ask Expression

The `ask` expression invokes an LLM:

```
ask_expr = "ask" expression [ask_modifiers]
ask_modifiers = typed_output | channel | retry_clause | fallback_clause
typed_output = "as" type
channel = "via" identifier
retry_clause = "with" "retries" ":" int_literal
fallback_clause = "fallback" expression
```

The expression must evaluate to a `String` (the prompt). The result type depends on modifiers.

**Basic ask:**
```
ask "What is the capital of France?"
ask "Summarize this text: {chunk}"
ask """
    Given the following context:
    {context}

    Answer the question: {question}
    """
```

**Typed output (structured responses):**
```
-- Returns List<String> instead of String
let fruits = ask "List 3 fruits as a JSON array" as List<String>

-- Returns a record type
let person = ask "Extract person info from: {text}" as {name: String, age: Int}

-- The runtime handles prompt formatting, parsing, and validation
```

Supported types for `as`:
- `String` (default)
- `Int`, `Bool`
- `List<T>` where T is a supported type
- `{field: Type, ...}` record types

The implementation automatically appends format instructions to the prompt and parses/validates the response.

**Named channels (multi-model routing):**
```
-- Route to different LLM configurations
let summary = ask "Summarize: {chunk}" via summarizer
let analysis = ask "Analyze sentiment: {summary}" via analyst
let final = ask "Combine insights: {analysis}" via coordinator
```

Channels are configured by the host environment, allowing different models, parameters, or system prompts per channel. If a channel is not configured, falls back to `default`.

**Retry with automatic backoff:**
```
-- Retry up to 3 times on failure
let result = ask "Complex extraction: {text}" with retries: 3
```

The implementation handles exponential backoff. Retries occur on:
- Parse failures (for typed output)
- Host callback errors marked as retryable
- Timeout errors

**Fallback chains:**
```
-- Try primary, fall back to simpler prompt, then default value
let answer = ask "Detailed analysis of: {complex_text}"
    fallback ask "Simple summary of: {complex_text}"
    fallback "Unable to process"
```

Fallback is invoked when the preceding `ask` fails (after retries if specified).

**Combining modifiers:**
```
let entities = ask "Extract entities from: {text}" as List<String>
    via extractor
    with retries: 2
    fallback []
```

Modifier evaluation order: channel → typed parsing → retry → fallback.

#### 4.3.9 Pipeline Syntax

Pipelines chain operations left-to-right:

```
context
  |> split by "\n\n"
  |> filter where length(it) > 100
  |> map with ask "Summarize: {it}"
  |> join with "\n"
```

This is pure syntax sugar and desugars to nested function calls.

### 4.4 Return Expression

Every program must end with a `return` expression specifying the output:

```
return_expr = "return" expression
```

```
return findings
return ask "Final answer based on: {evidence}"
return join results with "\n"
```

---

## 5. Type System

### 5.1 Base Types

| Type | Description | Examples |
|------|-------------|----------|
| `String` | Unicode text | `"hello"`, `""` |
| `Int` | Integer (arbitrary precision) | `42`, `-1`, `0` |
| `Bool` | Boolean | `true`, `false` |

### 5.2 Composite Types

| Type | Description | Examples |
|------|-------------|----------|
| `List<T>` | Ordered collection | `[1, 2, 3]`, `["a", "b"]` |
| `Optional<T>` | Present or absent | `Some("value")`, `None` |
| `Tuple<T, U, ...>` | Fixed-size heterogeneous | `(1, "a", true)` |
| `Record` | Named fields | `{name: "Alice", age: 30}` |

### 5.3 Type Inference

Hoist uses bidirectional type inference. Most type annotations can be omitted:

```
let x = 42                    -- Int
let name = "Alice"            -- String
let items = split text by "," -- List<String>
let first = items[0]          -- Optional<String>
```

### 5.4 Type Compatibility

The type system enforces:

- `ask` accepts `String`, returns `String`
- `map` over `List<T>` with `T → U` produces `List<U>`
- `filter` over `List<T>` with `T → Bool` produces `List<T>`
- `if` branches must have identical types
- String interpolation accepts any type with `show` conversion

### 5.5 Subtyping

Hoist has no subtyping. Types must match exactly (modulo inference).

### 5.6 Optional Handling

Safe indexing and operations that may fail return `Optional<T>`:

```
let first = items[0]  -- Optional<String>

-- Unwrap with default
let value = first or "default"

-- Unwrap with match
match first with
| Some(s) → "Got: {s}"
| None → "Empty"

-- Map over optional
let upper_first = map first with upper(it)  -- Optional<String>
```

---

## 6. Semantics

### 6.1 Evaluation Order

Hoist uses **strict evaluation** with **deterministic order**:

1. Bindings are evaluated top-to-bottom
2. Function arguments are evaluated left-to-right
3. Collection operations preserve input order

### 6.2 Purity

All expressions are pure (referentially transparent) except `ask`, which may return different results for the same prompt.

For reproducibility, implementations may provide a deterministic mode where `ask` results are cached or mocked.

### 6.3 Collection Semantics

**Map evaluation:**
```
map [a, b, c] with f
-- evaluates as: [f(a), f(b), f(c)]
```

Implementations MAY evaluate map elements in parallel when the mapping function is pure or when the host provides a parallel `ask` handler.

**Filter evaluation:**
```
filter [a, b, c] where p
-- evaluates as: [x | x ← [a,b,c], p(x)]
```

**Fold evaluation:**
```
fold [a, b, c] from z with f
-- evaluates as: f(f(f(z, a), b), c)
```

Fold is inherently sequential.

### 6.4 Ask Semantics

The `ask` expression is the only impure operation. Semantically:

1. The prompt string is fully evaluated
2. The prompt is passed to the host-provided ask handler
3. Execution suspends until the handler returns
4. The handler's return value (a string) becomes the expression's value

Implementations SHOULD support batching multiple independent `ask` calls for efficiency.

### 6.5 Error Handling

Hoist distinguishes between:

**Static errors** — Detected before execution:
- Syntax errors
- Type errors
- Unbound variables

**Runtime errors** — May occur during execution:
- Index out of bounds → returns `None`
- Division by zero → runtime error
- Ask handler failure → runtime error

Runtime errors abort execution. There is no exception handling; the embedding API reports errors to the host.

### 6.6 Termination Guarantee

Every well-typed Hoist program terminates because:

1. No unbounded loops
2. No general recursion
3. `fold`, `map`, `filter` only iterate over finite collections
4. `take` bounds collection size
5. No lazy evaluation or infinite data structures

The only source of non-termination is an `ask` handler that doesn't return, which is outside Hoist's control.

---

## 7. Standard Library

### 7.1 String Functions

| Function | Type | Description |
|----------|------|-------------|
| `length(s)` | `String → Int` | Character count |
| `upper(s)` | `String → String` | Uppercase |
| `lower(s)` | `String → String` | Lowercase |
| `trim(s)` | `String → String` | Remove leading/trailing whitespace |
| `trim_start(s)` | `String → String` | Remove leading whitespace |
| `trim_end(s)` | `String → String` | Remove trailing whitespace |
| `contains(s, sub)` | `String, String → Bool` | Substring test |
| `starts_with(s, pre)` | `String, String → Bool` | Prefix test |
| `ends_with(s, suf)` | `String, String → Bool` | Suffix test |
| `replace(s, old, new)` | `String, String, String → String` | Replace all occurrences |
| `chars(s)` | `String → List<String>` | Split into characters |
| `lines(s)` | `String → List<String>` | Split by newlines |
| `words(s)` | `String → List<String>` | Split by whitespace |

### 7.2 Regex Functions

| Function | Type | Description |
|----------|------|-------------|
| `matches(s, pattern)` | `String, String → Bool` | Test regex match |
| `find(s, pattern)` | `String, String → Optional<String>` | First match |
| `find_all(s, pattern)` | `String, String → List<String>` | All matches |
| `capture(s, pattern)` | `String, String → Optional<List<String>>` | Capture groups |

Regex syntax follows RE2 (linear-time guarantee, no backtracking catastrophe).

### 7.3 List Functions

| Function | Type | Description |
|----------|------|-------------|
| `length(xs)` | `List<T> → Int` | Element count |
| `empty(xs)` | `List<T> → Bool` | Test if empty |
| `first(xs)` | `List<T> → Optional<T>` | First element |
| `last(xs)` | `List<T> → Optional<T>` | Last element |
| `reverse(xs)` | `List<T> → List<T>` | Reverse order |
| `sort(xs)` | `List<String> → List<String>` | Lexicographic sort |
| `unique(xs)` | `List<T> → List<T>` | Remove duplicates |
| `flatten(xss)` | `List<List<T>> → List<T>` | Flatten one level |
| `zip(xs, ys)` | `List<T>, List<U> → List<Tuple<T,U>>` | Pair elements |
| `enumerate(xs)` | `List<T> → List<Tuple<Int, T>>` | Add indices |

### 7.4 Numeric Functions

| Function | Type | Description |
|----------|------|-------------|
| `abs(n)` | `Int → Int` | Absolute value |
| `min(a, b)` | `Int, Int → Int` | Minimum |
| `max(a, b)` | `Int, Int → Int` | Maximum |
| `clamp(n, lo, hi)` | `Int, Int, Int → Int` | Clamp to range |
| `sum(ns)` | `List<Int> → Int` | Sum of elements |

### 7.5 Conversion Functions

| Function | Type | Description |
|----------|------|-------------|
| `show(x)` | `T → String` | Convert to string |
| `parse_int(s)` | `String → Optional<Int>` | Parse integer |

### 7.6 Utility Functions

| Function | Type | Description |
|----------|------|-------------|
| `debug(x)` | `T → T` | Log value (passthrough) |
| `type_of(x)` | `T → String` | Runtime type name |

---

## 8. Execution Model

### 8.1 Compilation Phases

```
Source → Lexer → Tokens → Parser → AST → TypeChecker → TypedIR → Optimizer → ExecutableIR
```

1. **Lexing** — Source text to tokens
2. **Parsing** — Tokens to abstract syntax tree
3. **Type checking** — AST to typed intermediate representation
4. **Optimization** — Simplification, constant folding, ask batching
5. **Execution** — IR interpretation or code generation

### 8.2 Intermediate Representation

The typed IR represents the program as a directed acyclic graph (DAG) of operations:

```
Node types:
- Literal(value)
- Variable(name)
- Apply(function, args)
- Map(collection, binding, body)
- Filter(collection, binding, predicate)
- Fold(collection, init, acc_binding, elem_binding, body)
- Ask(prompt)
- If(condition, then_branch, else_branch)
```

Edges represent data dependencies. The IR explicitly shows parallelization opportunities.

### 8.3 Execution Strategy

**Sequential execution:**
1. Topologically sort the DAG
2. Evaluate nodes in dependency order
3. Execute `ask` nodes via host callback

**Parallel execution (optional):**
1. Identify independent `ask` nodes (no data dependency)
2. Batch independent asks into single host callback
3. Continue when all results return

Example: `map chunks with ask "summarize: {it}"` with 10 chunks can execute as:
- 10 sequential asks (simple), or
- 1 batched ask with 10 prompts (efficient)

The host's ask handler determines actual parallelism.

### 8.4 Resource Limits

Implementations MUST enforce configurable limits:

| Limit | Default | Description |
|-------|---------|-------------|
| `max_ask_calls` | 100 | Maximum ask invocations |
| `max_collection_size` | 10,000 | Maximum list length |
| `max_string_size` | 10 MB | Maximum string size |
| `max_execution_time` | 300s | Wall-clock timeout |

Exceeding limits causes a runtime error.

---

## 9. Embedding API

### 9.1 Core Interface

Every Hoist implementation MUST provide these operations:

```
interface Hoist {
    // Compile source to executable
    compile(source: String) → Result<Program, CompileError>

    // Type-check a program
    typecheck(program: Program) → Result<TypedProgram, TypeError>

    // Execute with context and ask handler
    execute(
        program: TypedProgram,
        context: String,
        ask_handler: (prompt: String) → String,
        limits: ResourceLimits?
    ) → Result<String, RuntimeError>
}
```

### 9.2 Error Types

**CompileError:**
```
{
    kind: "SyntaxError" | "ParseError",
    message: String,
    location: { line: Int, column: Int },
    source_snippet: String
}
```

**TypeError:**
```
{
    kind: "TypeMismatch" | "UnboundVariable" | "InvalidOperation",
    message: String,
    location: { line: Int, column: Int },
    expected: String?,
    actual: String?
}
```

**RuntimeError:**
```
{
    kind: "LimitExceeded" | "AskFailed" | "DivisionByZero",
    message: String,
    location: { line: Int, column: Int }?,
    context: Map<String, Any>
}
```

### 9.3 Ask Handler Contract

The ask handler provided by the host:

```
ask_handler: (prompt: String, options: AskOptions) → AskResult

AskOptions = {
    channel: String?,           -- Named channel (default: "default")
    expected_type: TypeSpec?,   -- For typed output parsing
    retry_count: Int?           -- Which retry attempt (0 = first try)
}

AskResult = {
    value: String,              -- Raw response
    parsed: Any?,               -- Parsed value if typed output requested
    metadata: {                 -- Optional metadata
        model: String?,
        tokens_used: Int?,
        latency_ms: Int?
    }?
}
```

- MUST return a result for any valid prompt
- MUST NOT have side effects visible to Hoist (from Hoist's perspective, ask is deterministic)
- MAY implement caching, batching, rate limiting internally
- MAY throw/return error to abort execution or trigger retry
- SHOULD use `channel` to route to different LLM configurations
- SHOULD use `expected_type` to format prompts and validate responses

### 9.4 Channel Configuration

Hosts configure named channels to route `ask` calls to different LLM backends:

```python
runtime = hoist.Runtime(
    channels={
        "default": lambda p, opts: call_gpt4(p),
        "summarizer": lambda p, opts: call_gpt35(p, max_tokens=200),
        "analyst": lambda p, opts: call_gpt4(p, temperature=0, system="You analyze data."),
        "coordinator": lambda p, opts: call_claude(p, system="You synthesize information."),
    }
)
```

Channel benefits:
- **Cost optimization** — Use cheaper models for simple tasks
- **Specialization** — Different system prompts per task type
- **A/B testing** — Route channels to different providers
- **Rate limiting** — Per-channel quotas

If a channel is not configured, the runtime uses the `default` channel.

### 9.5 Typed Output Handling

When `ask` includes `as Type`, the runtime:

1. Appends format instructions to the prompt:
   - `as List<String>` → "Respond with a JSON array of strings."
   - `as {name: String, age: Int}` → "Respond with JSON: {\"name\": string, \"age\": number}"

2. Parses the LLM response according to the type

3. Validates the parsed result matches the expected type

4. On parse/validation failure:
   - If `retries` specified, retry with clarifying prompt
   - If `fallback` specified, use fallback value
   - Otherwise, raise runtime error

Implementations MAY provide hooks for custom type formatters and parsers.

### 9.6 Batch Ask Handler (Optional)

For efficiency, implementations MAY support a batch handler:

```
batch_ask_handler: (prompts: List<String>) → List<String>
```

The implementation automatically batches independent ask operations.

### 9.7 Language Bindings

Reference bindings should follow host language conventions:

**Python:**
```python
from delvelang import compile, execute

program = compile(source)
result = execute(
    program,
    context=document_text,
    ask_handler=lambda prompt: openai.complete(prompt)
)
```

**JavaScript/TypeScript:**
```typescript
import { compile, execute } from 'delvelang';

const program = compile(source);
const result = await execute(program, {
    context: documentText,
    askHandler: async (prompt) => await openai.complete(prompt)
});
```

**Rust:**
```rust
use delvelang::{compile, execute, AskHandler};

let program = compile(source)?;
let result = execute(
    &program,
    context,
    |prompt| openai_complete(prompt)
)?;
```

---

## 10. Security Model

### 10.1 Threat Model

Hoist assumes:

- **Untrusted source code** — Programs may come from users or LLM output
- **Untrusted context** — Document content may be adversarial
- **Trusted host** — The embedding application controls the ask handler

### 10.2 Guarantees

**Memory safety:** No buffer overflows, use-after-free, or memory corruption.

**Termination:** Every program terminates (bounded by resource limits).

**Isolation:** No access to host filesystem, network, environment, or memory beyond provided context.

**Determinism:** Given the same inputs and ask handler responses, execution produces the same output.

### 10.3 Non-Guarantees

**Ask handler security:** Hoist cannot prevent the ask handler from being misused. Prompt injection attacks pass through to the handler.

**Timing:** Execution time may leak information about context content.

**Resource exhaustion:** Within limits, programs can consume significant CPU/memory.

### 10.4 Prompt Injection Mitigation

Hoist does not solve prompt injection, but supports mitigations:

1. **Interpolation escaping:** Implementations MAY provide an `escape(s)` function for sanitizing untrusted content before interpolation.

2. **Structured prompts:** The ask handler can receive structured data (prompt template + variables) instead of a flat string.

3. **Output validation:** Host code should validate ask results before trusting them.

### 10.5 Audit Logging

Implementations SHOULD support execution tracing:

```
{
    timestamp: "2026-01-22T10:30:00Z",
    event: "ask",
    prompt: "Summarize: ...",
    prompt_hash: "sha256:...",
    result_hash: "sha256:...",
    duration_ms: 1523
}
```

This enables forensic analysis without logging sensitive content.

---

## 11. Examples

### 11.1 Needle in Haystack

Find specific information in a large document:

```
-- Search for sections mentioning "secret code"
let chunks = split context by "\n\n"
let relevant = filter chunks where contains(it, "secret") or contains(it, "code")

-- If found via keyword, analyze those chunks
-- Otherwise, use sliding window
let candidates = if length(relevant) > 0
    then relevant
    else window context size 2000 stride 1500

-- Ask LLM to extract the code from each candidate
let analyses = map candidates with
    ask "Extract any secret code from this text. Reply NONE if not found:\n{it}"

-- Filter to actual findings
let findings = filter analyses where not contains(it, "NONE")

return if length(findings) > 0
    then ask "Consolidate these findings into a single answer:\n{join findings with \"\\n\"}"
    else "No secret code found"
```

### 11.2 Information Aggregation

Categorize and count items:

```
let entries = lines(context)

-- Classify each entry via LLM
let classifications = map entries with
    ask """Classify this question into exactly one category:
    - location (about places)
    - numeric (about numbers)
    - person (about people)
    - abbreviation (about acronyms)
    - description (about definitions)

    Question: {it}

    Reply with only the category name."""

-- Count by category
let locations = filter classifications where it == "location"
let numeric = filter classifications where it == "numeric"
let persons = filter classifications where it == "person"

return """Classification results:
- Locations: {length(locations)}
- Numeric: {length(numeric)}
- Persons: {length(persons)}
- Total: {length(entries)}"""
```

### 11.3 Multi-hop Reasoning

Answer questions requiring information from multiple sources:

```
-- Split into documents
let docs = split context by "=== Document"
let docs = filter docs where length(trim(it)) > 0

-- First pass: gather relevant facts
let facts = map docs with
    ask """Extract key facts from this document relevant to answering:
    "{question}"

    Document:
    {it}

    List facts as bullet points, or "No relevant facts" if none."""

-- Filter to documents with relevant info
let relevant_facts = filter facts where not contains(it, "No relevant facts")

-- Synthesize final answer
return ask """Based on these facts from multiple documents, answer the question.

Question: {question}

Facts gathered:
{join relevant_facts with "\n\n"}

Provide a comprehensive answer citing which facts you used."""
```

### 11.4 Structured Extraction

Extract structured data from unstructured text:

```
let sections = split context by "\n\n"

-- Extract entities from each section
let extractions = map sections with
    ask """Extract any named entities from this text as JSON:
    {{"people": [...], "places": [...], "organizations": [...]}}

    Text: {it}

    Reply with only valid JSON."""

-- Parse and merge (using string operations since we don't have JSON type)
let people = map extractions with
    match find(it, "\"people\":\\s*\\[(.*?)\\]") with
    | Some(m) → m
    | None → ""

let all_people = join people with ", "

return "Found people: {all_people}"
```

### 11.5 Recursive Summarization

Summarize a very long document hierarchically:

```
-- First level: chunk into sections
let chunks = window context size 4000 stride 3500

-- Summarize each chunk
let summaries = map chunks with
    ask "Summarize this section in 2-3 sentences:\n{it}"

-- If we have many summaries, summarize again
let final = if length(summaries) > 10
    then
        let grouped = window (join summaries with "\n\n") size 3000 stride 2500
        let meta_summaries = map grouped with
            ask "Consolidate these summaries:\n{it}"
        ask "Create a final summary from these points:\n{join meta_summaries with \"\\n\\n\"}"
    else
        ask "Create a final summary from these points:\n{join summaries with \"\\n\\n\"}"

return final
```

---

## Appendix A: Complete EBNF Grammar

```ebnf
(* Top-level *)
program     = { binding } return_expr ;
binding     = "let" identifier [ ":" type ] "=" expr ;
return_expr = "return" expr ;

(* Expressions *)
expr        = pipe_expr ;
pipe_expr   = or_expr { "|>" or_expr } ;
or_expr     = and_expr { "or" and_expr } ;
and_expr    = not_expr { "and" not_expr } ;
not_expr    = [ "not" ] cmp_expr ;
cmp_expr    = add_expr [ cmp_op add_expr ] ;
add_expr    = mul_expr { add_op mul_expr } ;
mul_expr    = unary_expr { mul_op unary_expr } ;
unary_expr  = [ "-" ] postfix_expr ;
postfix_expr = primary_expr { postfix_op } ;
primary_expr = literal
             | identifier
             | "(" expr ")"
             | "[" [ expr { "," expr } ] "]"
             | "{" [ field { "," field } ] "}"
             | if_expr
             | match_expr
             | map_expr
             | filter_expr
             | fold_expr
             | take_expr
             | drop_expr
             | split_expr
             | join_expr
             | window_expr
             | slice_expr
             | ask_expr ;

(* Operators *)
cmp_op      = "==" | "!=" | "<" | ">" | "<=" | ">=" ;
add_op      = "+" | "-" | "++" ;
mul_op      = "*" | "/" | "%" ;
postfix_op  = "[" expr "]" | "(" [ expr { "," expr } ] ")" | "." identifier ;

(* Complex expressions *)
if_expr     = "if" expr "then" expr "else" expr ;
match_expr  = "match" expr "with" { match_arm } ;
match_arm   = "|" pattern "→" expr ;
map_expr    = "map" expr "with" ( expr | identifier "→" expr ) ;
filter_expr = "filter" expr "where" expr ;
fold_expr   = "fold" expr "from" expr "with" identifier "," identifier "→" expr ;
take_expr   = "take" expr "from" expr ;
drop_expr   = "drop" expr "from" expr ;
split_expr  = "split" expr "by" expr ;
join_expr   = "join" expr "with" expr ;
window_expr = "window" expr "size" expr "stride" expr ;
slice_expr  = "slice" expr "from" expr "to" expr ;
ask_expr    = "ask" expr { ask_modifier } ;
ask_modifier = "as" type
             | "via" identifier
             | "with" "retries" ":" int_lit
             | "fallback" expr ;

(* Patterns *)
pattern     = "_"
            | identifier
            | literal
            | identifier "(" [ pattern { "," pattern } ] ")" ;

(* Types *)
type        = base_type | list_type | optional_type | tuple_type | record_type ;
base_type   = "String" | "Int" | "Bool" ;
list_type   = "List" "<" type ">" ;
optional_type = "Optional" "<" type ">" ;
tuple_type  = "Tuple" "<" type { "," type } ">" ;
record_type = "{" [ identifier ":" type { "," identifier ":" type } ] "}" ;

(* Literals *)
literal     = string_lit | int_lit | bool_lit ;
string_lit  = '"' { string_char | interp } '"' | '"""' { raw_char } '"""' ;
interp      = "{" expr "}" ;
int_lit     = digit { digit } ;
bool_lit    = "true" | "false" ;

(* Lexical *)
identifier  = ( letter | "_" ) { letter | digit | "_" } ;
letter      = "a".."z" | "A".."Z" | unicode_letter ;
digit       = "0".."9" ;
string_char = <any char except '"', '\', '{'> | escape_seq ;
escape_seq  = "\n" | "\r" | "\t" | "\\" | '\"' | "\{" ;
raw_char    = <any char except '"""'> ;

(* Whitespace and comments *)
whitespace  = " " | "\t" | "\n" | "\r" ;
comment     = "--" { <any char except newline> } newline
            | "{-" { <any char or nested comment> } "-}" ;
```

---

## Appendix B: Compliance Test Format

Implementations can verify correctness against the official test suite. Tests are JSON files:

### B.1 Parse Test

```json
{
    "type": "parse",
    "name": "simple_binding",
    "source": "let x = 42\nreturn x",
    "expected_ast": {
        "bindings": [
            {"name": "x", "value": {"literal": {"int": 42}}}
        ],
        "return": {"variable": "x"}
    }
}
```

### B.2 Type Test

```json
{
    "type": "typecheck",
    "name": "map_type_inference",
    "source": "let items = [\"a\", \"b\"]\nlet upper_items = map items with upper(it)\nreturn upper_items",
    "expected_type": "List<String>"
}
```

### B.3 Type Error Test

```json
{
    "type": "typecheck_error",
    "name": "type_mismatch_in_if",
    "source": "return if true then 42 else \"string\"",
    "expected_error": {
        "kind": "TypeMismatch",
        "message_contains": "branches must have same type"
    }
}
```

### B.4 Execution Test

```json
{
    "type": "execute",
    "name": "filter_and_count",
    "source": "let items = split context by \",\"\nlet long = filter items where length(it) > 3\nreturn show(length(long))",
    "context": "a,bb,ccc,dddd,eeeee",
    "ask_responses": {},
    "expected_output": "2"
}
```

### B.5 Execution with Ask Test

```json
{
    "type": "execute",
    "name": "simple_ask",
    "source": "return ask \"What is 2+2?\"",
    "context": "",
    "ask_responses": {
        "What is 2+2?": "4"
    },
    "expected_output": "4"
}
```

### B.6 Ask Prompt Capture Test

```json
{
    "type": "execute_capture_asks",
    "name": "map_with_ask_prompts",
    "source": "let items = [\"a\", \"b\"]\nreturn join (map items with ask \"Process: {it}\") with \",\"",
    "context": "",
    "ask_responses": {
        "Process: a": "A",
        "Process: b": "B"
    },
    "expected_asks": ["Process: a", "Process: b"],
    "expected_output": "A,B"
}
```

### B.7 Resource Limit Test

```json
{
    "type": "execute_error",
    "name": "ask_limit_exceeded",
    "source": "let items = split context by \",\"\nreturn join (map items with ask \"X\") with \",\"",
    "context": "1,2,3,4,5,6,7,8,9,10,11",
    "limits": {"max_ask_calls": 10},
    "expected_error": {
        "kind": "LimitExceeded",
        "message_contains": "ask"
    }
}
```

---

## Appendix C: Design Rationale

This appendix documents the key design decisions in Hoist and explains why alternatives were rejected.

### C.1 Why a Custom Language?

**Decision:** Create a new DSL rather than embed in or subset an existing language.

**Alternatives considered:**

| Alternative | Pros | Cons |
|-------------|------|------|
| Python subset | Familiar, huge ecosystem | Hard to secure (blocklist approach), too much to remove |
| Lisp/S-expressions | Simple parser, homoiconic | Poor readability for prompts, unfamiliar to most users |
| JSON-based DSL | Universal parsing, easy tooling | Verbose, poor ergonomics for text manipulation |
| Lua/Wren embedding | Battle-tested, embeddable | Still Turing-complete, safety requires runtime sandbox |
| CEL extension | Google-hardened, safe | Limited expressiveness, awkward LLM primitives |

**Why custom:** Starting from scratch allows safety by construction (allowlist, not blocklist). We include only what's needed for LLM orchestration—nothing more. The syntax can be optimized for the domain: pipelines, string interpolation, and `ask` as first-class constructs.

**Trade-off accepted:** More implementation effort upfront, but cleaner security story and better developer experience for the specific use case.

### C.2 Why Totality (Guaranteed Termination)?

**Decision:** No loops, no general recursion—only `map`/`filter`/`fold` over finite collections.

**Inspiration:** Dhall, Agda, total functional programming literature.

**Why it matters:**

1. **Security** — Cannot write infinite loops, even accidentally
2. **Resource bounds** — Execution time is O(n × k) where n = data size, k = ask calls
3. **Compliance** — Can prove to auditors that programs terminate
4. **Billing predictability** — No runaway LLM API costs

**What we give up:** Cannot express "retry until success" or "poll until condition." This is intentional—unbounded retry loops are dangerous in production and should be handled by the host application with proper circuit breakers.

### C.3 Why `ask` as Host Callback?

**Decision:** The `ask` primitive is implemented entirely by the host environment, not built into Hoist.

**Alternatives considered:**

- Built-in OpenAI/Anthropic client
- Pluggable provider system within Hoist
- URL-based fetch primitive

**Why host callback:**

1. **Separation of concerns** — Hoist handles orchestration logic; host handles LLM integration, auth, retries, caching
2. **Testability** — Mock `ask` with deterministic responses for unit tests
3. **Provider agnostic** — Same Hoist program works with any LLM
4. **Batching control** — Host can implement sophisticated batching without Hoist changes
5. **Security** — No network access in the language itself

### C.4 Why Strict (Eager) Evaluation?

**Decision:** All expressions evaluate immediately; no laziness.

**Alternatives considered:** Lazy evaluation (Haskell-style), optional laziness annotations.

**Why strict:**

1. **Predictable resource usage** — You know exactly when memory is allocated
2. **Easier debugging** — No thunk-related surprises or space leaks
3. **Better for parallelism** — Easier to identify independent `ask` calls when evaluation order is explicit
4. **Simpler mental model** — Users don't need to understand lazy evaluation

**Trade-off accepted:** Cannot express infinite streams. Not needed for this domain.

### C.5 Why Pipeline Syntax (`|>`)?

**Decision:** Include pipe operator as core syntax, not just a library function.

**Inspiration:** Elixir, F#, OCaml, PRQL, Unix pipes.

**Why built-in:**

1. **Matches mental model** — "Take context, split it, filter it, map over it" reads naturally left-to-right
2. **Reduces nesting** — `a |> b |> c` is clearer than `c(b(a))`
3. **LLM-friendly** — Easier for models to generate sequential pipelines than deeply nested function calls
4. **Consistency** — Everyone uses the same idiom

### C.6 Why Implicit `it` Binding?

**Decision:** In `map` and `filter`, `it` is automatically bound to the current element.

**Inspiration:** Kotlin's `it`, Groovy closures, Perl's `$_`.

**Why:**

```
-- With implicit it (concise)
filter items where length(it) > 0

-- With explicit binding (verbose)
filter items where item → length(item) > 0
```

Most lambdas have one parameter. Making the common case concise improves readability.

**Explicit binding still supported** for clarity when needed or when nesting would cause ambiguity.

### C.7 Why No Exception Handling?

**Decision:** Runtime errors abort execution. No `try`/`catch`.

**Why:**

1. **Simplicity** — Exception handling adds significant complexity
2. **Fail-fast is appropriate** — For LLM orchestration, partial results are usually not useful
3. **Host handles recovery** — The embedding application can retry the whole program if needed
4. **Encourages defensive programming** — Use `Optional` returns (e.g., `first(xs)` returns `Optional<T>`) instead of exceptions

### C.8 Why RE2 Regex?

**Decision:** Regular expressions follow RE2 semantics (linear time, no backtracking).

**Inspiration:** Google RE2, Rust regex crate.

**Why:**

1. **Security** — No ReDoS (catastrophic backtracking) attacks possible
2. **Predictable performance** — O(n) matching guaranteed
3. **Sufficient power** — RE2 handles 99% of practical patterns

**Trade-off accepted:** No backreferences, no lookahead/lookbehind. These are rarely needed for document processing and are the source of exponential blowup.

### C.9 Why No Mutability?

**Decision:** All bindings are immutable. No reassignment.

**Why:**

1. **Referential transparency** — Easier to reason about programs
2. **Parallelization** — No data races when executing `map` in parallel
3. **Debugging** — Variable values don't change unexpectedly
4. **Matches functional paradigm** — Consistent with `map`/`filter`/`fold` style

**Not a real limitation:** Programs are short-lived queries, not stateful applications. Immutability is natural here.

### C.10 Why Resource Limits in Host, Not Language?

**Decision:** Limits (max asks, max string size, timeout) are set by the host, not in Hoist syntax.

**Why:**

1. **Flexibility** — Different deployments have different constraints
2. **Defense in depth** — Even if Hoist has a bug, host limits cap damage
3. **Billing control** — Host can enforce per-user quotas
4. **Separation of concerns** — Resource policy is operational, not logical

---

## Appendix D: Future Considerations

The following features are under consideration for future versions:

### C.1 User-Defined Functions

```
fn summarize(text: String, style: String) → String =
    ask "Summarize in {style} style:\n{text}"

return summarize(context, "formal")
```

Requires careful design to maintain totality (no recursion).

### C.2 Structured Ask

```
ask {
    system: "You are a helpful assistant.",
    user: "Summarize: {chunk}",
    temperature: 0.0,
    max_tokens: 500
}
```

Enables fine-grained control over LLM parameters.

### C.3 Parallel Map Annotation

```
map chunks with @parallel ask "Summarize: {it}"
```

Explicit annotation for parallelization intent.

### C.4 JSON Type

Native JSON support for structured data extraction:

```
let data: JSON = parse_json(response)
return data.field.nested[0]
```

### C.5 Streaming Results

For long-running operations:

```
yield intermediate_result  -- stream partial output
return final_result
```

---

## Changelog

### Version 0.1.0-draft (January 2026)

- Initial draft specification
- Core language features
- Standard library definition
- Embedding API specification
- Security model documentation

---

## License

This specification is released under the Apache 2.0 License.

Implementations may use any license compatible with embedding the specification.

---

## Contributing

Contributions to the specification are welcome via the RFC process:

1. Open an issue describing the proposed change
2. Discuss with maintainers and community
3. Submit a pull request with spec amendments
4. Review period (minimum 2 weeks)
5. Merge upon consensus

---

*End of Hoist Specification*
